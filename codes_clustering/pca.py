# -*- coding: utf-8 -*-
"""PCA

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KAhyOpFM9Ee_VBjDerxm5Rg4-2OEkYa4

# **Import Necessary Libraries**
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA
sns.set_style('whitegrid')

from google.colab import drive
# Please mount your drive.
drive.mount('/content/drive')

"""# **Dataset Construction**"""

data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/1990-1.csv', header=None, index_col=[0])
mat=data.values
mat = mat[1:].astype(float)
mat.shape

plt.scatter(mat[0,:], mat[2,:])
plt.axis('equal')

plt.xticks(range(-10, 10, 5))
plt.yticks(range(-10, 10, 5))
plt.show()

"""# **Principal Component Analysis, PCA**"""

def get_pca_data(ss_data, n_components=2):
    pca = PCA(n_components=n_components)
    pca.fit(ss_data)

    return pca.transform(ss_data), pca

pca_mat, pca= get_pca_data(mat, n_components=100)
pca_mat.shape

def get_pd_from_pca(pca_data, cols=None):
    if cols is None:
        cols = ['pca_component_{}'.format(i+1) for i in range(pca_data.shape[1])]
    return pd.DataFrame(pca_data, columns=cols)

def print_variance_ratio(pca):
    print('variance_ratio: ', pca.explained_variance_ratio_)
    print('sum of variance_ratio: ', np.sum(pca.explained_variance_ratio_))

print_variance_ratio(pca)

cols = []
for i in range(1, 101):
    cols.append('pca_' + str(i))

pca_mat_pd = get_pd_from_pca(pca_mat, cols=cols)

pca_x= pca_mat_pd[cols]

pca_mat
print(pca_mat)
num_components = len(pca_mat)
print("Number of components:", num_components)

#pca_mat은 mat 데이터를 주성분 축으로 변환한 결과.

pca.components_
print(pca.components_)
num_components = len(pca.components_)
print("Number of components:", num_components)
#pca.components_는 주성분 축의 방향을 나타내는 벡터들.

pca.mean_
print(pca.mean_)
num_components = len(pca.mean_)
print("Number of components:", num_components)

pca.explained_variance_

num_explained_variance = len(pca.explained_variance_)
print("Number of explained_variance:", num_explained_variance)

pca = PCA(n_components=100)
pca.fit(mat)
X_pca=pca.transform(mat)
print("original shape: ", mat.shape)
print("transformed shape: ", pca_mat.shape)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

cols = []
for i in range(1, 127):
    cols.append('pca_' + str(i))

mat_pd = pd.DataFrame(mat, columns=cols)
#mat_pd['species'] = mat_pd['pca_1']
mat_pd.head(1000)

mat_new=pca.inverse_transform(pca_mat)
plt.scatter(mat[:,0],mat[:,1], alpha=0.2)
plt.scatter(mat_new[:,0], mat_new[:,1], alpha=0.8)
plt.axis('equal');

"""# **StamdardScaler**"""

from sklearn.preprocessing import StandardScaler

mat_ss = StandardScaler().fit_transform(mat)

mat[0]

mat_ss[0]

mat_ss[0].shape
#첫번째 행을 의미 길이가 126인 벡터를 의미

mat_ss[0].reshape(1,-1).shape

#첫번째 행만 따로 때서 하나의 행렬로

pca.transform(mat_ss[0].reshape(1,-1))

mat_pd_pca = get_pd_from_pca(pca_mat)
mat_pd_pca.head(1000)

sns.pairplot(mat_pd_pca,height=5,
             x_vars=['pca_component_1'],y_vars=['pca_component_3'])